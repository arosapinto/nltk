{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK VS SPACY VS STANZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\APinto\\anaconda3\\envs\\projeto_apspacy\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "import nltk\n",
    "\n",
    "# spaCy\n",
    "import spacy\n",
    "#from spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = \"St. Patrick’s Day, feast day (March 17) of St. Patrick, patron saint of Ireland. Born in Roman Britain in the late 4th century, he was kidnapped at the age of 16 and taken to Ireland as a slave. He escaped but returned about 432 CE to convert the Irish to Christianity. By the time of his death on March 17, 461, he had established monasteries, churches, and schools. Many legends grew up around him—for example, that he drove the snakes out of Ireland and used the shamrock to explain the Trinity. Ireland came to celebrate his day with religious services and feasts.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['St.',\n",
       " 'Patrick',\n",
       " '’',\n",
       " 's',\n",
       " 'Day',\n",
       " ',',\n",
       " 'feast',\n",
       " 'day',\n",
       " '(',\n",
       " 'March',\n",
       " '17',\n",
       " ')',\n",
       " 'of',\n",
       " 'St.',\n",
       " 'Patrick',\n",
       " ',',\n",
       " 'patron',\n",
       " 'saint',\n",
       " 'of',\n",
       " 'Ireland',\n",
       " '.',\n",
       " 'Born',\n",
       " 'in',\n",
       " 'Roman',\n",
       " 'Britain',\n",
       " 'in',\n",
       " 'the',\n",
       " 'late',\n",
       " '4th',\n",
       " 'century',\n",
       " ',',\n",
       " 'he',\n",
       " 'was',\n",
       " 'kidnapped',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " '16',\n",
       " 'and',\n",
       " 'taken',\n",
       " 'to',\n",
       " 'Ireland',\n",
       " 'as',\n",
       " 'a',\n",
       " 'slave',\n",
       " '.',\n",
       " 'He',\n",
       " 'escaped',\n",
       " 'but',\n",
       " 'returned',\n",
       " 'about',\n",
       " '432',\n",
       " 'CE',\n",
       " 'to',\n",
       " 'convert',\n",
       " 'the',\n",
       " 'Irish',\n",
       " 'to',\n",
       " 'Christianity',\n",
       " '.',\n",
       " 'By',\n",
       " 'the',\n",
       " 'time',\n",
       " 'of',\n",
       " 'his',\n",
       " 'death',\n",
       " 'on',\n",
       " 'March',\n",
       " '17',\n",
       " ',',\n",
       " '461',\n",
       " ',',\n",
       " 'he',\n",
       " 'had',\n",
       " 'established',\n",
       " 'monasteries',\n",
       " ',',\n",
       " 'churches',\n",
       " ',',\n",
       " 'and',\n",
       " 'schools',\n",
       " '.',\n",
       " 'Many',\n",
       " 'legends',\n",
       " 'grew',\n",
       " 'up',\n",
       " 'around',\n",
       " 'him—for',\n",
       " 'example',\n",
       " ',',\n",
       " 'that',\n",
       " 'he',\n",
       " 'drove',\n",
       " 'the',\n",
       " 'snakes',\n",
       " 'out',\n",
       " 'of',\n",
       " 'Ireland',\n",
       " 'and',\n",
       " 'used',\n",
       " 'the',\n",
       " 'shamrock',\n",
       " 'to',\n",
       " 'explain',\n",
       " 'the',\n",
       " 'Trinity',\n",
       " '.',\n",
       " 'Ireland',\n",
       " 'came',\n",
       " 'to',\n",
       " 'celebrate',\n",
       " 'his',\n",
       " 'day',\n",
       " 'with',\n",
       " 'religious',\n",
       " 'services',\n",
       " 'and',\n",
       " 'feasts',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['St. Patrick’s Day, feast day (March 17) of St. Patrick, patron saint of Ireland.', 'Born in Roman Britain in the late 4th century, he was kidnapped at the age of 16 and taken to Ireland as a slave.', 'He escaped but returned about 432 CE to convert the Irish to Christianity.', 'By the time of his death on March 17, 461, he had established monasteries, churches, and schools.', 'Many legends grew up around him—for example, that he drove the snakes out of Ireland and used the shamrock to explain the Trinity.', 'Ireland came to celebrate his day with religious services and feasts.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "print(sent_tokenize(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St.\n",
      "Patrick\n",
      "’s\n",
      "Day\n",
      ",\n",
      "feast\n",
      "day\n",
      "(\n",
      "March\n",
      "17\n",
      ")\n",
      "of\n",
      "St.\n",
      "Patrick\n",
      ",\n",
      "patron\n",
      "saint\n",
      "of\n",
      "Ireland\n",
      ".\n",
      "Born\n",
      "in\n",
      "Roman\n",
      "Britain\n",
      "in\n",
      "the\n",
      "late\n",
      "4th\n",
      "century\n",
      ",\n",
      "he\n",
      "was\n",
      "kidnapped\n",
      "at\n",
      "the\n",
      "age\n",
      "of\n",
      "16\n",
      "and\n",
      "taken\n",
      "to\n",
      "Ireland\n",
      "as\n",
      "a\n",
      "slave\n",
      ".\n",
      "He\n",
      "escaped\n",
      "but\n",
      "returned\n",
      "about\n",
      "432\n",
      "CE\n",
      "to\n",
      "convert\n",
      "the\n",
      "Irish\n",
      "to\n",
      "Christianity\n",
      ".\n",
      "By\n",
      "the\n",
      "time\n",
      "of\n",
      "his\n",
      "death\n",
      "on\n",
      "March\n",
      "17\n",
      ",\n",
      "461\n",
      ",\n",
      "he\n",
      "had\n",
      "established\n",
      "monasteries\n",
      ",\n",
      "churches\n",
      ",\n",
      "and\n",
      "schools\n",
      ".\n",
      "Many\n",
      "legends\n",
      "grew\n",
      "up\n",
      "around\n",
      "him\n",
      "—\n",
      "for\n",
      "example\n",
      ",\n",
      "that\n",
      "he\n",
      "drove\n",
      "the\n",
      "snakes\n",
      "out\n",
      "of\n",
      "Ireland\n",
      "and\n",
      "used\n",
      "the\n",
      "shamrock\n",
      "to\n",
      "explain\n",
      "the\n",
      "Trinity\n",
      ".\n",
      "Ireland\n",
      "came\n",
      "to\n",
      "celebrate\n",
      "his\n",
      "day\n",
      "with\n",
      "religious\n",
      "services\n",
      "and\n",
      "feasts\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(str)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St. Patrick’s Day, feast day (March 17) of St. Patrick, patron saint of Ireland.\n",
      "Born in Roman Britain in the late 4th century, he was kidnapped at the age of 16 and taken to Ireland as a slave.\n",
      "He escaped but returned about 432 CE to convert the Irish to Christianity.\n",
      "By the time of his death on March 17, 461, he had established monasteries, churches, and schools.\n",
      "Many legends grew up around him—for example, that he drove the snakes out of Ireland and used the shamrock to explain the Trinity.\n",
      "Ireland came to celebrate his day with religious services and feasts.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(str)\n",
    "sent = nltk.sent_tokenize(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('St. Patrick’s Day, feast day (March 17) of St. Patrick, patron saint of Ireland.',\n",
       "  'NNP'),\n",
       " ('Born in Roman Britain in the late 4th century, he was kidnapped at the age of 16 and taken to Ireland as a slave.',\n",
       "  'NNP'),\n",
       " ('He escaped but returned about 432 CE to convert the Irish to Christianity.',\n",
       "  'NNP'),\n",
       " ('By the time of his death on March 17, 461, he had established monasteries, churches, and schools.',\n",
       "  'NNP'),\n",
       " ('Many legends grew up around him—for example, that he drove the snakes out of Ireland and used the shamrock to explain the Trinity.',\n",
       "  'NNP'),\n",
       " ('Ireland came to celebrate his day with religious services and feasts.',\n",
       "  'NNP')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags = nltk.pos_tag(tokens)\n",
    "pos_tags\n",
    "sent_tags = nltk.pos_tag(sent)\n",
    "sent_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('St.', 'NNP'),\n",
       " ('Patrick', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('Day', 'NNP'),\n",
       " (',', ','),\n",
       " ('feast', 'RB'),\n",
       " ('day', 'NN'),\n",
       " ('(', '('),\n",
       " ('March', 'NNP'),\n",
       " ('17', 'CD'),\n",
       " (')', ')'),\n",
       " ('of', 'IN'),\n",
       " ('St.', 'NNP'),\n",
       " ('Patrick', 'NNP'),\n",
       " (',', ','),\n",
       " ('patron', 'NN'),\n",
       " ('saint', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Ireland', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Born', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Roman', 'NNP'),\n",
       " ('Britain', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('late', 'JJ'),\n",
       " ('4th', 'JJ'),\n",
       " ('century', 'NN'),\n",
       " (',', ','),\n",
       " ('he', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('kidnapped', 'VBN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('age', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('16', 'CD'),\n",
       " ('and', 'CC'),\n",
       " ('taken', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('Ireland', 'NNP'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('slave', 'NN'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('escaped', 'VBD'),\n",
       " ('but', 'CC'),\n",
       " ('returned', 'VBD'),\n",
       " ('about', 'IN'),\n",
       " ('432', 'CD'),\n",
       " ('CE', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('convert', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('Irish', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('Christianity', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('By', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('death', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('March', 'NNP'),\n",
       " ('17', 'CD'),\n",
       " (',', ','),\n",
       " ('461', 'CD'),\n",
       " (',', ','),\n",
       " ('he', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('established', 'VBN'),\n",
       " ('monasteries', 'NNS'),\n",
       " (',', ','),\n",
       " ('churches', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('schools', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Many', 'JJ'),\n",
       " ('legends', 'NNS'),\n",
       " ('grew', 'VBD'),\n",
       " ('up', 'RP'),\n",
       " ('around', 'IN'),\n",
       " ('him—for', 'JJ'),\n",
       " ('example', 'NN'),\n",
       " (',', ','),\n",
       " ('that', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('drove', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('snakes', 'NNS'),\n",
       " ('out', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('Ireland', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('used', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('shamrock', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('explain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('Trinity', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Ireland', 'NNP'),\n",
       " ('came', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('celebrate', 'VB'),\n",
       " ('his', 'PRP$'),\n",
       " ('day', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('religious', 'JJ'),\n",
       " ('services', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('feasts', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = preprocess(str)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St. PROPN\n",
      "Patrick PROPN\n",
      "’s PART\n",
      "Day PROPN\n",
      ", PUNCT\n",
      "feast NOUN\n",
      "day NOUN\n",
      "( PUNCT\n",
      "March PROPN\n",
      "17 NUM\n",
      ") PUNCT\n",
      "of ADP\n",
      "St. PROPN\n",
      "Patrick PROPN\n",
      ", PUNCT\n",
      "patron NOUN\n",
      "saint NOUN\n",
      "of ADP\n",
      "Ireland PROPN\n",
      ". PUNCT\n",
      "Born VERB\n",
      "in ADP\n",
      "Roman PROPN\n",
      "Britain PROPN\n",
      "in ADP\n",
      "the DET\n",
      "late ADJ\n",
      "4th ADJ\n",
      "century NOUN\n",
      ", PUNCT\n",
      "he PRON\n",
      "was AUX\n",
      "kidnapped VERB\n",
      "at ADP\n",
      "the DET\n",
      "age NOUN\n",
      "of ADP\n",
      "16 NUM\n",
      "and CCONJ\n",
      "taken VERB\n",
      "to ADP\n",
      "Ireland PROPN\n",
      "as ADP\n",
      "a DET\n",
      "slave NOUN\n",
      ". PUNCT\n",
      "He PRON\n",
      "escaped VERB\n",
      "but CCONJ\n",
      "returned VERB\n",
      "about ADV\n",
      "432 NUM\n",
      "CE PROPN\n",
      "to PART\n",
      "convert VERB\n",
      "the DET\n",
      "Irish PROPN\n",
      "to ADP\n",
      "Christianity PROPN\n",
      ". PUNCT\n",
      "By ADP\n",
      "the DET\n",
      "time NOUN\n",
      "of ADP\n",
      "his PRON\n",
      "death NOUN\n",
      "on ADP\n",
      "March PROPN\n",
      "17 NUM\n",
      ", PUNCT\n",
      "461 NUM\n",
      ", PUNCT\n",
      "he PRON\n",
      "had AUX\n",
      "established VERB\n",
      "monasteries NOUN\n",
      ", PUNCT\n",
      "churches NOUN\n",
      ", PUNCT\n",
      "and CCONJ\n",
      "schools NOUN\n",
      ". PUNCT\n",
      "Many ADJ\n",
      "legends NOUN\n",
      "grew VERB\n",
      "up ADP\n",
      "around ADP\n",
      "him PRON\n",
      "— PUNCT\n",
      "for ADP\n",
      "example NOUN\n",
      ", PUNCT\n",
      "that SCONJ\n",
      "he PRON\n",
      "drove VERB\n",
      "the DET\n",
      "snakes NOUN\n",
      "out ADP\n",
      "of ADP\n",
      "Ireland PROPN\n",
      "and CCONJ\n",
      "used VERB\n",
      "the DET\n",
      "shamrock NOUN\n",
      "to PART\n",
      "explain VERB\n",
      "the DET\n",
      "Trinity PROPN\n",
      ". PUNCT\n",
      "Ireland PROPN\n",
      "came VERB\n",
      "to PART\n",
      "celebrate VERB\n",
      "his PRON\n",
      "day NOUN\n",
      "with ADP\n",
      "religious ADJ\n",
      "services NOUN\n",
      "and CCONJ\n",
      "feasts NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St. Patrick’s Day\n",
      "feast day\n",
      "(March\n",
      "St. Patrick\n",
      "patron saint\n",
      "Ireland\n",
      "Roman Britain\n",
      "the late 4th century\n",
      "he\n",
      "the age\n",
      "Ireland\n",
      "a slave\n",
      "He\n",
      "about 432 CE\n",
      "the Irish\n",
      "Christianity\n",
      "the time\n",
      "his death\n",
      "March\n",
      "he\n",
      "monasteries\n",
      "churches\n",
      "schools\n",
      "Many legends\n",
      "him\n",
      "example\n",
      "he\n",
      "the snakes\n",
      "Ireland\n",
      "the shamrock\n",
      "the Trinity\n",
      "Ireland\n",
      "his day\n",
      "religious services\n",
      "feasts\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install svgling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,904.0,168.0\" width=\"904px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"7.07965%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Pierre</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.53982%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"12.3894%\" x=\"7.07965%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ORGANIZATION</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Vinken</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.2743%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"2.65487%\" x=\"19.469%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.7965%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.53982%\" x=\"22.1239%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">61</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"23.8938%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.19469%\" x=\"25.6637%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">years</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.7611%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.42478%\" x=\"31.8584%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">old</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.0708%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"2.65487%\" x=\"36.2832%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"37.6106%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.30973%\" x=\"38.9381%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">will</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">MD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"41.5929%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.30973%\" x=\"44.2478%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">join</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"46.9027%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.42478%\" x=\"49.5575%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"51.7699%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.19469%\" x=\"53.9823%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">board</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.0796%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.53982%\" x=\"60.177%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">as</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.9469%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.53982%\" x=\"63.7168%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.4867%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"12.3894%\" x=\"67.2566%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">nonexecutive</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"73.4513%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"8.84956%\" x=\"79.646%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">director</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.0708%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.30973%\" x=\"88.4956%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Nov.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"91.1504%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.53982%\" x=\"93.8053%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">29</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"95.5752%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"2.65487%\" x=\"97.3451%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.6726%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Pierre', 'NNP')]), Tree('ORGANIZATION', [('Vinken', 'NNP')]), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CHUNKING\n",
    "#   which segments and labels multi-token sequences\n",
    "\n",
    "#nltk.download('treebank')\n",
    "from nltk.corpus import treebank_chunk # https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "from nltk.chunk import ne_chunk\n",
    "ne_chunk(treebank_chunk.tagged_sents()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NE St./NNP Patrick/NNP)\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  Day/NNP\n",
      "  ,/,\n",
      "  feast/RB\n",
      "  day/NN\n",
      "  (/(\n",
      "  March/NNP\n",
      "  17/CD\n",
      "  )/)\n",
      "  of/IN\n",
      "  (NE St./NNP Patrick/NNP)\n",
      "  ,/,\n",
      "  patron/NN\n",
      "  saint/NN\n",
      "  of/IN\n",
      "  (NE Ireland/NNP)\n",
      "  ./.\n",
      "  Born/NNP\n",
      "  in/IN\n",
      "  (NE Roman/NNP Britain/NNP)\n",
      "  in/IN\n",
      "  the/DT\n",
      "  late/JJ\n",
      "  4th/JJ\n",
      "  century/NN\n",
      "  ,/,\n",
      "  he/PRP\n",
      "  was/VBD\n",
      "  kidnapped/VBN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  age/NN\n",
      "  of/IN\n",
      "  16/CD\n",
      "  and/CC\n",
      "  taken/VBN\n",
      "  to/TO\n",
      "  (NE Ireland/NNP)\n",
      "  as/IN\n",
      "  a/DT\n",
      "  slave/NN\n",
      "  ./.\n",
      "  He/PRP\n",
      "  escaped/VBD\n",
      "  but/CC\n",
      "  returned/VBD\n",
      "  about/IN\n",
      "  432/CD\n",
      "  CE/NNP\n",
      "  to/TO\n",
      "  convert/VB\n",
      "  the/DT\n",
      "  (NE Irish/JJ)\n",
      "  to/TO\n",
      "  Christianity/NNP\n",
      "  ./.\n",
      "  By/IN\n",
      "  the/DT\n",
      "  time/NN\n",
      "  of/IN\n",
      "  his/PRP$\n",
      "  death/NN\n",
      "  on/IN\n",
      "  March/NNP\n",
      "  17/CD\n",
      "  ,/,\n",
      "  461/CD\n",
      "  ,/,\n",
      "  he/PRP\n",
      "  had/VBD\n",
      "  established/VBN\n",
      "  monasteries/NNS\n",
      "  ,/,\n",
      "  churches/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  schools/NNS\n",
      "  ./.\n",
      "  Many/JJ\n",
      "  legends/NNS\n",
      "  grew/VBD\n",
      "  up/RP\n",
      "  around/IN\n",
      "  him—for/JJ\n",
      "  example/NN\n",
      "  ,/,\n",
      "  that/IN\n",
      "  he/PRP\n",
      "  drove/VBD\n",
      "  the/DT\n",
      "  snakes/NNS\n",
      "  out/IN\n",
      "  of/IN\n",
      "  (NE Ireland/NNP)\n",
      "  and/CC\n",
      "  used/VBD\n",
      "  the/DT\n",
      "  shamrock/NN\n",
      "  to/TO\n",
      "  explain/VB\n",
      "  the/DT\n",
      "  (NE Trinity/NNP)\n",
      "  ./.\n",
      "  (NE Ireland/NNP)\n",
      "  came/VBD\n",
      "  to/TO\n",
      "  celebrate/VB\n",
      "  his/PRP$\n",
      "  day/NN\n",
      "  with/IN\n",
      "  religious/JJ\n",
      "  services/NNS\n",
      "  and/CC\n",
      "  feasts/NNS\n",
      "  ./.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\APinto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "print(nltk.ne_chunk(pos_tags, binary=True)) # nltk.ne_chunk(), we can recognize named entities using a classifier, the classifier adds category labels such as PERSON, ORGANIZATION, and GPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  St./NNP\n",
      "  Patrick/NNP\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  Day/NNP\n",
      "  ,/,\n",
      "  feast/RB\n",
      "  (NP day/NN)\n",
      "  (/(\n",
      "  March/NNP\n",
      "  17/CD\n",
      "  )/)\n",
      "  of/IN\n",
      "  St./NNP\n",
      "  Patrick/NNP\n",
      "  ,/,\n",
      "  (NP patron/NN)\n",
      "  (NP saint/NN)\n",
      "  of/IN\n",
      "  Ireland/NNP\n",
      "  ./.\n",
      "  Born/NNP\n",
      "  in/IN\n",
      "  Roman/NNP\n",
      "  Britain/NNP\n",
      "  in/IN\n",
      "  (NP the/DT late/JJ 4th/JJ century/NN)\n",
      "  ,/,\n",
      "  he/PRP\n",
      "  was/VBD\n",
      "  kidnapped/VBN\n",
      "  at/IN\n",
      "  (NP the/DT age/NN)\n",
      "  of/IN\n",
      "  16/CD\n",
      "  and/CC\n",
      "  taken/VBN\n",
      "  to/TO\n",
      "  Ireland/NNP\n",
      "  as/IN\n",
      "  (NP a/DT slave/NN)\n",
      "  ./.\n",
      "  He/PRP\n",
      "  escaped/VBD\n",
      "  but/CC\n",
      "  returned/VBD\n",
      "  about/IN\n",
      "  432/CD\n",
      "  CE/NNP\n",
      "  to/TO\n",
      "  convert/VB\n",
      "  the/DT\n",
      "  Irish/JJ\n",
      "  to/TO\n",
      "  Christianity/NNP\n",
      "  ./.\n",
      "  By/IN\n",
      "  (NP the/DT time/NN)\n",
      "  of/IN\n",
      "  his/PRP$\n",
      "  (NP death/NN)\n",
      "  on/IN\n",
      "  March/NNP\n",
      "  17/CD\n",
      "  ,/,\n",
      "  461/CD\n",
      "  ,/,\n",
      "  he/PRP\n",
      "  had/VBD\n",
      "  established/VBN\n",
      "  monasteries/NNS\n",
      "  ,/,\n",
      "  churches/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  schools/NNS\n",
      "  ./.\n",
      "  Many/JJ\n",
      "  legends/NNS\n",
      "  grew/VBD\n",
      "  up/RP\n",
      "  around/IN\n",
      "  (NP him—for/JJ example/NN)\n",
      "  ,/,\n",
      "  that/IN\n",
      "  he/PRP\n",
      "  drove/VBD\n",
      "  the/DT\n",
      "  snakes/NNS\n",
      "  out/IN\n",
      "  of/IN\n",
      "  Ireland/NNP\n",
      "  and/CC\n",
      "  used/VBD\n",
      "  (NP the/DT shamrock/NN)\n",
      "  to/TO\n",
      "  explain/VB\n",
      "  the/DT\n",
      "  Trinity/NNP\n",
      "  ./.\n",
      "  Ireland/NNP\n",
      "  came/VBD\n",
      "  to/TO\n",
      "  celebrate/VB\n",
      "  his/PRP$\n",
      "  (NP day/NN)\n",
      "  with/IN\n",
      "  religious/JJ\n",
      "  services/NNS\n",
      "  and/CC\n",
      "  feasts/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "pattern = 'NP: {<DT>?<JJ>*<NN>}' #  a noun phrase, NP, should be formed whenever the chunker finds an optional determiner, DT, followed by any number of adjectives, JJ, and then a noun, NN.\n",
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('St.', 'NNP', 'O'),\n",
      " ('Patrick', 'NNP', 'O'),\n",
      " ('’', 'NNP', 'O'),\n",
      " ('s', 'VBD', 'O'),\n",
      " ('Day', 'NNP', 'O'),\n",
      " (',', ',', 'O'),\n",
      " ('feast', 'RB', 'O'),\n",
      " ('day', 'NN', 'B-NP'),\n",
      " ('(', '(', 'O'),\n",
      " ('March', 'NNP', 'O'),\n",
      " ('17', 'CD', 'O'),\n",
      " (')', ')', 'O'),\n",
      " ('of', 'IN', 'O'),\n",
      " ('St.', 'NNP', 'O'),\n",
      " ('Patrick', 'NNP', 'O'),\n",
      " (',', ',', 'O'),\n",
      " ('patron', 'NN', 'B-NP'),\n",
      " ('saint', 'NN', 'B-NP'),\n",
      " ('of', 'IN', 'O'),\n",
      " ('Ireland', 'NNP', 'O'),\n",
      " ('.', '.', 'O'),\n",
      " ('Born', 'NNP', 'O'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('Roman', 'NNP', 'O'),\n",
      " ('Britain', 'NNP', 'O'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('late', 'JJ', 'I-NP'),\n",
      " ('4th', 'JJ', 'I-NP'),\n",
      " ('century', 'NN', 'I-NP'),\n",
      " (',', ',', 'O'),\n",
      " ('he', 'PRP', 'O'),\n",
      " ('was', 'VBD', 'O'),\n",
      " ('kidnapped', 'VBN', 'O'),\n",
      " ('at', 'IN', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('age', 'NN', 'I-NP'),\n",
      " ('of', 'IN', 'O'),\n",
      " ('16', 'CD', 'O'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('taken', 'VBN', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('Ireland', 'NNP', 'O'),\n",
      " ('as', 'IN', 'O'),\n",
      " ('a', 'DT', 'B-NP'),\n",
      " ('slave', 'NN', 'I-NP'),\n",
      " ('.', '.', 'O'),\n",
      " ('He', 'PRP', 'O'),\n",
      " ('escaped', 'VBD', 'O'),\n",
      " ('but', 'CC', 'O'),\n",
      " ('returned', 'VBD', 'O'),\n",
      " ('about', 'IN', 'O'),\n",
      " ('432', 'CD', 'O'),\n",
      " ('CE', 'NNP', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('convert', 'VB', 'O'),\n",
      " ('the', 'DT', 'O'),\n",
      " ('Irish', 'JJ', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('Christianity', 'NNP', 'O'),\n",
      " ('.', '.', 'O'),\n",
      " ('By', 'IN', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('time', 'NN', 'I-NP'),\n",
      " ('of', 'IN', 'O'),\n",
      " ('his', 'PRP$', 'O'),\n",
      " ('death', 'NN', 'B-NP'),\n",
      " ('on', 'IN', 'O'),\n",
      " ('March', 'NNP', 'O'),\n",
      " ('17', 'CD', 'O'),\n",
      " (',', ',', 'O'),\n",
      " ('461', 'CD', 'O'),\n",
      " (',', ',', 'O'),\n",
      " ('he', 'PRP', 'O'),\n",
      " ('had', 'VBD', 'O'),\n",
      " ('established', 'VBN', 'O'),\n",
      " ('monasteries', 'NNS', 'O'),\n",
      " (',', ',', 'O'),\n",
      " ('churches', 'NNS', 'O'),\n",
      " (',', ',', 'O'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('schools', 'NNS', 'O'),\n",
      " ('.', '.', 'O'),\n",
      " ('Many', 'JJ', 'O'),\n",
      " ('legends', 'NNS', 'O'),\n",
      " ('grew', 'VBD', 'O'),\n",
      " ('up', 'RP', 'O'),\n",
      " ('around', 'IN', 'O'),\n",
      " ('him—for', 'JJ', 'B-NP'),\n",
      " ('example', 'NN', 'I-NP'),\n",
      " (',', ',', 'O'),\n",
      " ('that', 'IN', 'O'),\n",
      " ('he', 'PRP', 'O'),\n",
      " ('drove', 'VBD', 'O'),\n",
      " ('the', 'DT', 'O'),\n",
      " ('snakes', 'NNS', 'O'),\n",
      " ('out', 'IN', 'O'),\n",
      " ('of', 'IN', 'O'),\n",
      " ('Ireland', 'NNP', 'O'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('used', 'VBD', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('shamrock', 'NN', 'I-NP'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('explain', 'VB', 'O'),\n",
      " ('the', 'DT', 'O'),\n",
      " ('Trinity', 'NNP', 'O'),\n",
      " ('.', '.', 'O'),\n",
      " ('Ireland', 'NNP', 'O'),\n",
      " ('came', 'VBD', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('celebrate', 'VB', 'O'),\n",
      " ('his', 'PRP$', 'O'),\n",
      " ('day', 'NN', 'B-NP'),\n",
      " ('with', 'IN', 'O'),\n",
      " ('religious', 'JJ', 'O'),\n",
      " ('services', 'NNS', 'O'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('feasts', 'NNS', 'O'),\n",
      " ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "### IOB tags \n",
    "\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(St. Patrick’s Day, 'FAC', 9191306739292312949),\n",
       " (feast day, 'DATE', 391),\n",
       " (March 17, 'DATE', 391),\n",
       " (St. Patrick, 'GPE', 384),\n",
       " (Ireland, 'GPE', 384),\n",
       " (Roman Britain, 'GPE', 384),\n",
       " (the late 4th century, 'DATE', 391),\n",
       " (the age of 16, 'DATE', 391),\n",
       " (Ireland, 'GPE', 384),\n",
       " (about 432, 'CARDINAL', 397),\n",
       " (Irish, 'NORP', 381),\n",
       " (Christianity, 'NORP', 381),\n",
       " (March 17, 'DATE', 391),\n",
       " (461, 'CARDINAL', 397),\n",
       " (Ireland, 'GPE', 384),\n",
       " (Trinity, 'ORG', 383),\n",
       " (Ireland, 'PERSON', 380)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = [(i, i.label_, i.label) for i in doc.ents]\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St. Patrick’s Day             FAC                 Buildings, airports, highways, bridges, etc.\n",
      "feast day                     DATE                Absolute or relative dates or periods\n",
      "March 17                      DATE                Absolute or relative dates or periods\n",
      "St. Patrick                   GPE                 Countries, cities, states\n",
      "Ireland                       GPE                 Countries, cities, states\n",
      "Roman Britain                 GPE                 Countries, cities, states\n",
      "the late 4th century          DATE                Absolute or relative dates or periods\n",
      "the age of 16                 DATE                Absolute or relative dates or periods\n",
      "Ireland                       GPE                 Countries, cities, states\n",
      "about 432                     CARDINAL            Numerals that do not fall under another type\n",
      "Irish                         NORP                Nationalities or religious or political groups\n",
      "Christianity                  NORP                Nationalities or religious or political groups\n",
      "March 17                      DATE                Absolute or relative dates or periods\n",
      "461                           CARDINAL            Numerals that do not fall under another type\n",
      "Ireland                       GPE                 Countries, cities, states\n",
      "Trinity                       ORG                 Companies, agencies, institutions, etc.\n",
      "Ireland                       PERSON              People, including fictional\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text:<{30}}{entity.label_:<{20}}{(spacy.explain(entity.label_))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(St., 3, 'B', 'FAC'), (Patrick, 1, 'I', 'FAC'), (’s, 1, 'I', 'FAC'), (Day, 1, 'I', 'FAC'), (,, 2, 'O', ''), (feast, 3, 'B', 'DATE'), (day, 1, 'I', 'DATE'), ((, 2, 'O', ''), (March, 3, 'B', 'DATE'), (17, 1, 'I', 'DATE'), (), 2, 'O', ''), (of, 2, 'O', ''), (St., 3, 'B', 'GPE'), (Patrick, 1, 'I', 'GPE'), (,, 2, 'O', ''), (patron, 2, 'O', ''), (saint, 2, 'O', ''), (of, 2, 'O', ''), (Ireland, 3, 'B', 'GPE'), (., 2, 'O', ''), (Born, 2, 'O', ''), (in, 2, 'O', ''), (Roman, 3, 'B', 'GPE'), (Britain, 1, 'I', 'GPE'), (in, 2, 'O', ''), (the, 3, 'B', 'DATE'), (late, 1, 'I', 'DATE'), (4th, 1, 'I', 'DATE'), (century, 1, 'I', 'DATE'), (,, 2, 'O', ''), (he, 2, 'O', ''), (was, 2, 'O', ''), (kidnapped, 2, 'O', ''), (at, 2, 'O', ''), (the, 3, 'B', 'DATE'), (age, 1, 'I', 'DATE'), (of, 1, 'I', 'DATE'), (16, 1, 'I', 'DATE'), (and, 2, 'O', ''), (taken, 2, 'O', ''), (to, 2, 'O', ''), (Ireland, 3, 'B', 'GPE'), (as, 2, 'O', ''), (a, 2, 'O', ''), (slave, 2, 'O', ''), (., 2, 'O', ''), (He, 2, 'O', ''), (escaped, 2, 'O', ''), (but, 2, 'O', ''), (returned, 2, 'O', ''), (about, 3, 'B', 'CARDINAL'), (432, 1, 'I', 'CARDINAL'), (CE, 2, 'O', ''), (to, 2, 'O', ''), (convert, 2, 'O', ''), (the, 2, 'O', ''), (Irish, 3, 'B', 'NORP'), (to, 2, 'O', ''), (Christianity, 3, 'B', 'NORP'), (., 2, 'O', ''), (By, 2, 'O', ''), (the, 2, 'O', ''), (time, 2, 'O', ''), (of, 2, 'O', ''), (his, 2, 'O', ''), (death, 2, 'O', ''), (on, 2, 'O', ''), (March, 3, 'B', 'DATE'), (17, 1, 'I', 'DATE'), (,, 2, 'O', ''), (461, 3, 'B', 'CARDINAL'), (,, 2, 'O', ''), (he, 2, 'O', ''), (had, 2, 'O', ''), (established, 2, 'O', ''), (monasteries, 2, 'O', ''), (,, 2, 'O', ''), (churches, 2, 'O', ''), (,, 2, 'O', ''), (and, 2, 'O', ''), (schools, 2, 'O', ''), (., 2, 'O', ''), (Many, 2, 'O', ''), (legends, 2, 'O', ''), (grew, 2, 'O', ''), (up, 2, 'O', ''), (around, 2, 'O', ''), (him, 2, 'O', ''), (—, 2, 'O', ''), (for, 2, 'O', ''), (example, 2, 'O', ''), (,, 2, 'O', ''), (that, 2, 'O', ''), (he, 2, 'O', ''), (drove, 2, 'O', ''), (the, 2, 'O', ''), (snakes, 2, 'O', ''), (out, 2, 'O', ''), (of, 2, 'O', ''), (Ireland, 3, 'B', 'GPE'), (and, 2, 'O', ''), (used, 2, 'O', ''), (the, 2, 'O', ''), (shamrock, 2, 'O', ''), (to, 2, 'O', ''), (explain, 2, 'O', ''), (the, 2, 'O', ''), (Trinity, 3, 'B', 'ORG'), (., 2, 'O', ''), (Ireland, 3, 'B', 'PERSON'), (came, 2, 'O', ''), (to, 2, 'O', ''), (celebrate, 2, 'O', ''), (his, 2, 'O', ''), (day, 2, 'O', ''), (with, 2, 'O', ''), (religious, 2, 'O', ''), (services, 2, 'O', ''), (and, 2, 'O', ''), (feasts, 2, 'O', ''), (., 2, 'O', '')]\n"
     ]
    }
   ],
   "source": [
    "print([(i, i.ent_iob, i.ent_iob_, i.ent_type_) for i in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming: removes affixis and prefixis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============SNOWBALL STEMMER================\n",
      "St. --------> st.\n",
      "Patrick’s --------> patrick’\n",
      "Day, --------> day,\n",
      "feast --------> feast\n",
      "day --------> day\n",
      "(March --------> (march\n",
      "17) --------> 17)\n",
      "of --------> of\n",
      "St. --------> st.\n",
      "Patrick, --------> patrick,\n",
      "patron --------> patron\n",
      "saint --------> saint\n",
      "of --------> of\n",
      "Ireland. --------> ireland.\n",
      "Born --------> born\n",
      "in --------> in\n",
      "Roman --------> roman\n",
      "Britain --------> britain\n",
      "in --------> in\n",
      "the --------> the\n",
      "late --------> late\n",
      "4th --------> 4th\n",
      "century, --------> century,\n",
      "he --------> he\n",
      "was --------> wa\n",
      "kidnapped --------> kidnap\n",
      "at --------> at\n",
      "the --------> the\n",
      "age --------> age\n",
      "of --------> of\n",
      "16 --------> 16\n",
      "and --------> and\n",
      "taken --------> taken\n",
      "to --------> to\n",
      "Ireland --------> ireland\n",
      "as --------> as\n",
      "a --------> a\n",
      "slave. --------> slave.\n",
      "He --------> he\n",
      "escaped --------> escap\n",
      "but --------> but\n",
      "returned --------> return\n",
      "about --------> about\n",
      "432 --------> 432\n",
      "CE --------> ce\n",
      "to --------> to\n",
      "convert --------> convert\n",
      "the --------> the\n",
      "Irish --------> irish\n",
      "to --------> to\n",
      "Christianity. --------> christianity.\n",
      "By --------> by\n",
      "the --------> the\n",
      "time --------> time\n",
      "of --------> of\n",
      "his --------> hi\n",
      "death --------> death\n",
      "on --------> on\n",
      "March --------> march\n",
      "17, --------> 17,\n",
      "461, --------> 461,\n",
      "he --------> he\n",
      "had --------> had\n",
      "established --------> establish\n",
      "monasteries, --------> monasteries,\n",
      "churches, --------> churches,\n",
      "and --------> and\n",
      "schools. --------> schools.\n",
      "Many --------> mani\n",
      "legends --------> legend\n",
      "grew --------> grew\n",
      "up --------> up\n",
      "around --------> around\n",
      "him—for --------> him—for\n",
      "example, --------> example,\n",
      "that --------> that\n",
      "he --------> he\n",
      "drove --------> drove\n",
      "the --------> the\n",
      "snakes --------> snake\n",
      "out --------> out\n",
      "of --------> of\n",
      "Ireland --------> ireland\n",
      "and --------> and\n",
      "used --------> use\n",
      "the --------> the\n",
      "shamrock --------> shamrock\n",
      "to --------> to\n",
      "explain --------> explain\n",
      "the --------> the\n",
      "Trinity. --------> trinity.\n",
      "Ireland --------> ireland\n",
      "came --------> came\n",
      "to --------> to\n",
      "celebrate --------> celebr\n",
      "his --------> hi\n",
      "day --------> day\n",
      "with --------> with\n",
      "religious --------> religi\n",
      "services --------> servic\n",
      "and --------> and\n",
      "feasts. --------> feasts.\n",
      "===============PORTER STEMMER================\n",
      "St. --------> st.\n",
      "Patrick’s --------> patrick\n",
      "Day, --------> day,\n",
      "feast --------> feast\n",
      "day --------> day\n",
      "(March --------> (march\n",
      "17) --------> 17)\n",
      "of --------> of\n",
      "St. --------> st.\n",
      "Patrick, --------> patrick,\n",
      "patron --------> patron\n",
      "saint --------> saint\n",
      "of --------> of\n",
      "Ireland. --------> ireland.\n",
      "Born --------> born\n",
      "in --------> in\n",
      "Roman --------> roman\n",
      "Britain --------> britain\n",
      "in --------> in\n",
      "the --------> the\n",
      "late --------> late\n",
      "4th --------> 4th\n",
      "century, --------> century,\n",
      "he --------> he\n",
      "was --------> was\n",
      "kidnapped --------> kidnap\n",
      "at --------> at\n",
      "the --------> the\n",
      "age --------> age\n",
      "of --------> of\n",
      "16 --------> 16\n",
      "and --------> and\n",
      "taken --------> taken\n",
      "to --------> to\n",
      "Ireland --------> ireland\n",
      "as --------> as\n",
      "a --------> a\n",
      "slave. --------> slave.\n",
      "He --------> he\n",
      "escaped --------> escap\n",
      "but --------> but\n",
      "returned --------> return\n",
      "about --------> about\n",
      "432 --------> 432\n",
      "CE --------> ce\n",
      "to --------> to\n",
      "convert --------> convert\n",
      "the --------> the\n",
      "Irish --------> irish\n",
      "to --------> to\n",
      "Christianity. --------> christianity.\n",
      "By --------> by\n",
      "the --------> the\n",
      "time --------> time\n",
      "of --------> of\n",
      "his --------> his\n",
      "death --------> death\n",
      "on --------> on\n",
      "March --------> march\n",
      "17, --------> 17,\n",
      "461, --------> 461,\n",
      "he --------> he\n",
      "had --------> had\n",
      "established --------> establish\n",
      "monasteries, --------> monasteries,\n",
      "churches, --------> churches,\n",
      "and --------> and\n",
      "schools. --------> schools.\n",
      "Many --------> mani\n",
      "legends --------> legend\n",
      "grew --------> grew\n",
      "up --------> up\n",
      "around --------> around\n",
      "him—for --------> him—for\n",
      "example, --------> example,\n",
      "that --------> that\n",
      "he --------> he\n",
      "drove --------> drove\n",
      "the --------> the\n",
      "snakes --------> snake\n",
      "out --------> out\n",
      "of --------> of\n",
      "Ireland --------> ireland\n",
      "and --------> and\n",
      "used --------> use\n",
      "the --------> the\n",
      "shamrock --------> shamrock\n",
      "to --------> to\n",
      "explain --------> explain\n",
      "the --------> the\n",
      "Trinity. --------> trinity.\n",
      "Ireland --------> ireland\n",
      "came --------> came\n",
      "to --------> to\n",
      "celebrate --------> celebr\n",
      "his --------> his\n",
      "day --------> day\n",
      "with --------> with\n",
      "religious --------> religi\n",
      "services --------> servic\n",
      "and --------> and\n",
      "feasts. --------> feasts.\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "print('===============SNOWBALL STEMMER================')\n",
    "for word in str.split():\n",
    "    print(f\"{word} --------> {p_stemmer.stem(word)}\")\n",
    "\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "print('===============PORTER STEMMER================')\n",
    "for word in str.split():\n",
    "    print(f\"{word} --------> {s_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('St.', 'St.', 16623299875770883202), ('Patrick', 'Patrick', 6111389899429789079), ('’s', '’s', 614914527630368944), ('Day', 'Day', 13415491272735578485), (',', ',', 2593208677638477497), ('feast', 'feast', 11186993949197835975), ('day', 'day', 1608482186128794349), ('(', '(', 12638816674900267446), ('March', 'March', 2800013963164483082), ('17', '17', 6675425533856447351), (')', ')', 3842344029291005339), ('of', 'of', 886050111519832510), ('St.', 'St.', 16623299875770883202), ('Patrick', 'Patrick', 6111389899429789079), (',', ',', 2593208677638477497), ('patron', 'patron', 5918748221166822696), ('saint', 'saint', 4222591378771001924), ('of', 'of', 886050111519832510), ('Ireland', 'Ireland', 16197944773895086232), ('.', '.', 12646065887601541794), ('Born', 'bear', 3737373500888618661), ('in', 'in', 3002984154512732771), ('Roman', 'Roman', 313188162254974305), ('Britain', 'Britain', 9199405576633879440), ('in', 'in', 3002984154512732771), ('the', 'the', 7425985699627899538), ('late', 'late', 7199752172782760331), ('4th', '4th', 5593150423833315037), ('century', 'century', 11624174997366784379), (',', ',', 2593208677638477497), ('he', 'he', 1655312771067108281), ('was', 'be', 10382539506755952630), ('kidnapped', 'kidnap', 8278098946009648237), ('at', 'at', 11667289587015813222), ('the', 'the', 7425985699627899538), ('age', 'age', 10400321950887182855), ('of', 'of', 886050111519832510), ('16', '16', 4206877449096176963), ('and', 'and', 2283656566040971221), ('taken', 'take', 6789454535283781228), ('to', 'to', 3791531372978436496), ('Ireland', 'Ireland', 16197944773895086232), ('as', 'as', 7437575085468336610), ('a', 'a', 11901859001352538922), ('slave', 'slave', 14489702253140395053), ('.', '.', 12646065887601541794), ('He', 'he', 1655312771067108281), ('escaped', 'escape', 3455369559004845828), ('but', 'but', 14560795576765492085), ('returned', 'return', 9563260825101828504), ('about', 'about', 942632335873952620), ('432', '432', 2102888793712770166), ('CE', 'CE', 13271677230856618211), ('to', 'to', 3791531372978436496), ('convert', 'convert', 3335942246579838762), ('the', 'the', 7425985699627899538), ('Irish', 'Irish', 1395241404165252482), ('to', 'to', 3791531372978436496), ('Christianity', 'Christianity', 851344760084651526), ('.', '.', 12646065887601541794), ('By', 'by', 16764210730586636600), ('the', 'the', 7425985699627899538), ('time', 'time', 8885804376230376864), ('of', 'of', 886050111519832510), ('his', 'his', 2661093235354845946), ('death', 'death', 17835866735480682125), ('on', 'on', 5640369432778651323), ('March', 'March', 2800013963164483082), ('17', '17', 6675425533856447351), (',', ',', 2593208677638477497), ('461', '461', 4699903116460498265), (',', ',', 2593208677638477497), ('he', 'he', 1655312771067108281), ('had', 'have', 14692702688101715474), ('established', 'establish', 1940088560065702450), ('monasteries', 'monastery', 11129673356309097152), (',', ',', 2593208677638477497), ('churches', 'church', 477211971893892074), (',', ',', 2593208677638477497), ('and', 'and', 2283656566040971221), ('schools', 'school', 13293160603192985325), ('.', '.', 12646065887601541794), ('Many', 'many', 9720044723474553187), ('legends', 'legend', 17067105940613322182), ('grew', 'grow', 17623831665190758874), ('up', 'up', 2199259611705938403), ('around', 'around', 3194226484742107227), ('him', 'he', 1655312771067108281), ('—', '—', 13657828488461764581), ('for', 'for', 16037325823156266367), ('example', 'example', 899618643364689362), (',', ',', 2593208677638477497), ('that', 'that', 4380130941430378203), ('he', 'he', 1655312771067108281), ('drove', 'drive', 9588452728179957059), ('the', 'the', 7425985699627899538), ('snakes', 'snake', 9728857013107038949), ('out', 'out', 1696981056005371314), ('of', 'of', 886050111519832510), ('Ireland', 'Ireland', 16197944773895086232), ('and', 'and', 2283656566040971221), ('used', 'use', 6873750497785110593), ('the', 'the', 7425985699627899538), ('shamrock', 'shamrock', 15849967691627759351), ('to', 'to', 3791531372978436496), ('explain', 'explain', 8012976192951462851), ('the', 'the', 7425985699627899538), ('Trinity', 'Trinity', 10622350073458913812), ('.', '.', 12646065887601541794), ('Ireland', 'Ireland', 16197944773895086232), ('came', 'come', 5307304325359566725), ('to', 'to', 3791531372978436496), ('celebrate', 'celebrate', 12366391553231041167), ('his', 'his', 2661093235354845946), ('day', 'day', 1608482186128794349), ('with', 'with', 12510949447758279278), ('religious', 'religious', 2158901299127206455), ('services', 'service', 208172016153456603), ('and', 'and', 2283656566040971221), ('feasts', 'feast', 11186993949197835975), ('.', '.', 12646065887601541794)]\n"
     ]
    }
   ],
   "source": [
    "print([(token.text, token.lemma_, token.lemma) for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner'],\n",
       " [('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x165173fefa0>),\n",
       "  ('tagger', <spacy.pipeline.tagger.Tagger at 0x165173fed60>),\n",
       "  ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1651715ec80>),\n",
       "  ('attribute_ruler',\n",
       "   <spacy.pipeline.attributeruler.AttributeRuler at 0x165174b2f00>),\n",
       "  ('lemmatizer',\n",
       "   <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x165174c0e40>),\n",
       "  ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1651715ee40>)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names, nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK_OF_ART')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = nlp.get_pipe('ner').labels\n",
    "ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STOP WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'besides', 'ourselves', 'where', 'thence', 'becomes', 'get', 'because', 'top', 'yourself', 'amongst', 'several', 'mostly', 'from', 'seem', '‘m', 'your', 'together', 'myself', 'else', 'are', 'even', 'therein', 'same', 'up', 'forty', 'anything', 'five', \"'ll\", \"'re\", 'various', 'out', 'here', 'whence', 'without', 'beside', 'under', 'wherein', 'who', 'others', 'can', 'yours', 'on', 'an', 'did', 'still', 'with', 'n‘t', 'be', 'her', 'across', 'about', 'call', 'us', 'other', 'two', 'empty', 'few', 'afterwards', 'really', 'me', 'via', 'onto', 'fifteen', 'you', 'every', 'always', 'toward', 'why', 'part', 'already', 'above', 'their', 'before', 'whither', 'anywhere', 'formerly', 'may', 'due', '’s', 'also', 'again', 'noone', 'which', 'become', 'thereupon', 'regarding', 'last', 'elsewhere', 'otherwise', 'upon', 'nothing', 'thereafter', 'n’t', 'whereby', 'another', '‘ve', 'whose', 'then', 'once', 'make', 'until', 'less', 'themselves', 'whatever', 'its', 'my', 'by', 'ten', 'third', 'nine', 'she', 'thereby', 'over', 'rather', 'into', 'any', 'latter', 'both', 'anyway', 'through', '’re', 'mine', 'how', 'whereafter', \"n't\", 'ever', 'whole', 'yet', 'as', 'these', 'his', 'hence', 'had', 'anyhow', 'just', 'beyond', 'cannot', 'at', 'might', 'some', 'put', 'we', 'whom', 'seemed', 'further', 'per', 'has', 'whereas', 'well', \"'s\", 'for', \"'m\", 'seeming', 'doing', 'him', 'was', 'however', 'ours', 'now', 'should', 'against', 'all', 'a', 'everywhere', 'itself', 'after', 'yourselves', 'made', 'amount', 'or', 'around', 'former', 'serious', 'hereafter', 'hereby', 'our', 'neither', 'six', 'much', 'the', 'quite', 'since', 'never', 'down', 'indeed', '‘d', 'himself', 'whereupon', '’ve', 'unless', 'show', 'own', 'nevertheless', 'many', 'so', 'anyone', 'bottom', 'would', '’d', 'among', 'whether', 'take', 'while', 'namely', 'am', 'used', '’m', 'sometime', 'back', 'latterly', 'nowhere', 'everyone', 'and', 'eight', 'one', 'seems', 'hundred', 'fifty', 'front', 'between', 'i', 'next', 'using', '‘s', 'done', 'please', 'side', 'will', 'say', 'within', 'alone', 'either', 'in', 'give', 'twenty', 're', 'go', 'perhaps', 'see', 'during', \"'ve\", 'when', 'very', 'below', 'hereupon', 'thus', 'twelve', 'more', 'therefore', 'became', 'although', 'they', 'no', '‘re', 'been', 'hers', 'whoever', 'least', 'four', 'must', 'beforehand', 'off', 'wherever', 'if', 'were', 'them', 'somehow', 'keep', 'throughout', 'name', 'too', 'could', 'nor', 'but', 'nobody', 'being', 'than', 'have', 'almost', 'often', 'it', 'thru', 'everything', 'none', 'somewhere', 'only', 'not', 'sixty', 'whenever', 'that', '’ll', 'each', 'something', '‘ll', 'first', \"'d\", 'behind', 'herself', 'enough', 'except', 'is', 'those', 'such', 'meanwhile', 'three', 'most', 'moreover', 'eleven', 'full', 'becoming', 'though', 'does', 'sometimes', 'what', 'to', 'he', 'do', 'there', 'of', 'towards', 'move', 'along', 'someone', 'herein', 'ca', 'this'}\n",
      "326\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)\n",
    "print(len(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('St.', False), ('Patrick', False), ('’s', True), ('Day', False), (',', False), ('feast', False), ('day', False), ('(', False), ('March', False), ('17', False), (')', False), ('of', True), ('St.', False), ('Patrick', False), (',', False), ('patron', False), ('saint', False), ('of', True), ('Ireland', False), ('.', False), ('Born', False), ('in', True), ('Roman', False), ('Britain', False), ('in', True), ('the', True), ('late', False), ('4th', False), ('century', False), (',', False), ('he', True), ('was', True), ('kidnapped', False), ('at', True), ('the', True), ('age', False), ('of', True), ('16', False), ('and', True), ('taken', False), ('to', True), ('Ireland', False), ('as', True), ('a', True), ('slave', False), ('.', False), ('He', True), ('escaped', False), ('but', True), ('returned', False), ('about', True), ('432', False), ('CE', False), ('to', True), ('convert', False), ('the', True), ('Irish', False), ('to', True), ('Christianity', False), ('.', False), ('By', True), ('the', True), ('time', False), ('of', True), ('his', True), ('death', False), ('on', True), ('March', False), ('17', False), (',', False), ('461', False), (',', False), ('he', True), ('had', True), ('established', False), ('monasteries', False), (',', False), ('churches', False), (',', False), ('and', True), ('schools', False), ('.', False), ('Many', True), ('legends', False), ('grew', False), ('up', True), ('around', True), ('him', True), ('—', False), ('for', True), ('example', False), (',', False), ('that', True), ('he', True), ('drove', False), ('the', True), ('snakes', False), ('out', True), ('of', True), ('Ireland', False), ('and', True), ('used', True), ('the', True), ('shamrock', False), ('to', True), ('explain', False), ('the', True), ('Trinity', False), ('.', False), ('Ireland', False), ('came', False), ('to', True), ('celebrate', False), ('his', True), ('day', False), ('with', True), ('religious', False), ('services', False), ('and', True), ('feasts', False), ('.', False)]\n"
     ]
    }
   ],
   "source": [
    "print([(token.text, token.is_stop) for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where               : is stop word: True\n",
      "was                 : is stop word: True\n",
      "u                   : is stop word: False\n",
      "?                   : is stop word: False\n",
      "I                   : is stop word: True\n",
      "was                 : is stop word: True\n",
      "looking             : is stop word: False\n",
      "for                 : is stop word: True\n",
      "you                 : is stop word: True\n",
      "btw                 : is stop word: True\n",
      "session...          : is stop word: False\n",
      "Where               : is stop word: True\n",
      "was                 : is stop word: True\n",
      "u                   : is stop word: False\n",
      "?                   : is stop word: False\n",
      "I                   : is stop word: True\n",
      "was                 : is stop word: True\n",
      "looking             : is stop word: False\n",
      "for                 : is stop word: False\n",
      "you                 : is stop word: True\n",
      "btw                 : is stop word: True\n",
      "session...          : is stop word: False\n"
     ]
    }
   ],
   "source": [
    "# Possible to add and remove stopwords\n",
    "# We can add our own stop word\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "nlp.Defaults.stop_words.add('u')\n",
    "\n",
    "sentence = 'Where was u ? I was looking for you btw session...'\n",
    "for word in sentence.split():\n",
    "    print(f\"{word:{20}}: is stop word: {nlp.vocab[word].is_stop}\")\n",
    "\n",
    "# We can also remove stop word\n",
    "nlp.vocab['for'].is_stop = False\n",
    "sentence = 'Where was u ? I was looking for you btw session...'\n",
    "for word in sentence.split():\n",
    "    print(f\"{word:{20}}: is stop word: {nlp.vocab[word].is_stop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford named entity recognizer\n",
    "\n",
    "- Stanford NER is a Java implementation of a Named Entity Recognizer. \n",
    "- Included with the download are good named entity recognizers for English, particularly for the 3 classes (PERSON, ORGANIZATION, LOCATION)\n",
    "- Stanford NER is also known as CRFClassifier. The software provides a general implementation of (arbitrary order) linear chain Conditional Random Field (CRF) sequence models. That is, by training your own models on labeled data, you can actually use this code to build sequence models for NER or any other task\n",
    "\n",
    "\n",
    "NLTK (2.0+) contains an interface to Stanford NER written by Nitin Madnani: documentation (note: set the character encoding or you get ASCII by default!), code, on Github.\n",
    "\n",
    "#### MODELS:\n",
    "\n",
    "-Included with Stanford NER are a 4 class model trained on the CoNLL 2003 eng.train, a 7 class model trained on the MUC 6 and MUC 7 training data sets, and a 3 class model trained on both data sets and some additional data (including ACE 2002 and limited amounts of in-house data) on the intersection of those class sets. (The training data for the 3 class model does not include any material from the CoNLL eng.testa or eng.testb data sets, nor any of the MUC 6 or 7 test or devtest datasets, nor Alan Ritter's Twitter NER data, so all of these remain valid tests of its performance.)\n",
    "\n",
    "    3 class:\tLocation, Person, Organization\n",
    "    4 class:\tLocation, Person, Organization, Misc\n",
    "    7 class:\tLocation, Person, Organization, Money, Percent, Date, Time\n",
    "\n",
    "\n",
    "http://corenlp.run/\n",
    "\n",
    "### Has:\n",
    "\n",
    " - POS \n",
    " - COREFERENCE\n",
    " - LEMMAS\n",
    " - NER:  LOCATION / ORGANIZATION / DATE / MONEY  /   PERSON /  PERCENT / TIME\n",
    " - CONSTITUENCY PARSE\n",
    " - DEPENDENCE PARSE\n",
    " - OPENIE\n",
    " - RELATIONS: https://nlp.stanford.edu/projects/kbp/\n",
    " - SENTIMENT: NEUTRAL, POSITIVE AND NEGATIVE\n",
    "\n",
    "\n",
    "### STANZA\n",
    "In 2020, Stanford released STANZA, Python library based on Stanford NLP. You can find it here https://stanfordnlp.github.io/stanza/\n",
    "Stanza is a collection of accurate and efficient tools for the linguistic analysis of many human languages. Starting from raw text to syntactic analysis and entity recognition, Stanza brings state-of-the-art NLP models to languages of your choosing.\n",
    "\n",
    "- TEM MODELOS PARA DIFERENTES IDIOMAS: Universal Dependencies (UD) models\n",
    "- Não tem NER para português \n",
    "For packages with 4 named entity types, supported types include PER (Person), LOC (Location), ORG (Organization) and MISC (Miscellaneous) 2b. The Vietnamese VLSP model spells out the entire tag, though: PERSON, LOCATION, ORGANIZATION, MISCELLANEOUS.\n",
    "- For packages with 18 named entity types, supported types include PERSON, NORP (Nationalities/religious/political group), FAC (Facility), ORG (Organization), GPE (Countries/cities/states), LOC (Location), PRODUCT,EVENT, WORK_OF_ART, LAW, LANGUAGE, DATE, TIME, PERCENT, MONEY, QUANTITY, ORDINAL and CARDINAL\n",
    "- Possible to create new models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stanza vs CoreNLP: What are the differences?\n",
    "\n",
    "- What is Stanza? A Python NLP Library for Many Human Languages. It is a Python natural language analysis package. It contains tools, which can be used in a pipeline, to convert a string containing human language text into lists of sentences and words, to generate base forms of those words, their parts of speech and morphological features, to give a syntactic structure dependency parse, and to recognize named entities. The toolkit is designed to be parallel among more than 70 languages, using the Universal Dependencies formalism.\n",
    "\n",
    "- What is CoreNLP? A set of human language technology tools. It provides a set of natural language analysis tools written in Java. It can take raw human language text input and give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize and interpret dates, times, and numeric quantities, mark up the structure of sentences in terms of phrases or word dependencies, and indicate which noun phrases refer to the same entities.\n",
    "\n",
    "- Stanza and CoreNLP can be primarily classified as \"NLP / Sentiment Analysis\" tools.\n",
    "\n",
    "- Some of the features offered by Stanza are:\n",
    "    - Native Python implementation requiring minimal efforts to set up\n",
    "    - Full neural network pipeline for robust text analytics, including tokenization, multi-word token (MWT) expansion, lemmatization, part-of-speech (POS) and morphological features tagging, dependency parsing, and named entity recognition\n",
    "    - Pretrained neural models supporting 66 (human) languages\n",
    "\n",
    "- On the other hand, CoreNLP provides the following key features:\n",
    "    - An integrated NLP toolkit with a broad range of grammatical analysis tools\n",
    "    - A fast, robust annotator for arbitrary texts, widely used in production\n",
    "    - A modern, regularly updated package, with the overall highest quality text analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy vs Stanza: What are the differences?\n",
    "\n",
    "What is SpaCy? Industrial-Strength Natural Language Processing in Python. It is a library for advanced Natural Language Processing in Python and Cython. It's built on the very latest research, and was designed from day one to be used in real products. It comes with pre-trained statistical models and word vectors, and currently supports tokenization for 49+ languages.\n",
    "\n",
    "What is Stanza? A Python NLP Library for Many Human Languages. It is a Python natural language analysis package. It contains tools, which can be used in a pipeline, to convert a string containing human language text into lists of sentences and words, to generate base forms of those words, their parts of speech and morphological features, to give a syntactic structure dependency parse, and to recognize named entities. The toolkit is designed to be parallel among more than 70 languages, using the Universal Dependencies formalism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stanza\n",
    "import stanza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 12:09:10 WARNING: Language pt package default expects mwt, which has been added\n",
      "2022-05-06 12:09:10 INFO: Loading these models for language: pt (Portuguese):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | bosque  |\n",
      "| mwt       | bosque  |\n",
      "| pos       | bosque  |\n",
      "| lemma     | bosque  |\n",
      "=======================\n",
      "\n",
      "2022-05-06 12:09:10 INFO: Use device: cpu\n",
      "2022-05-06 12:09:10 INFO: Loading: tokenize\n",
      "2022-05-06 12:09:10 INFO: Loading: mwt\n",
      "2022-05-06 12:09:10 INFO: Loading: pos\n",
      "2022-05-06 12:09:11 INFO: Loading: lemma\n",
      "2022-05-06 12:09:11 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "#stanza.download('pt') # download English model\n",
    "#nlp = stanza.Pipeline('pt') # initialize English neural pipeline\n",
    "nlp = stanza.Pipeline('pt', processors='tokenize,pos,lemma') #not ner for pt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pttext = 'No interior tranquilo e verdejante há um Algarve diferente que esconde aldeias tradicionais e paisagens espetaculares. O caminho para chegar a este mundo preservado? Nada mais fácil… é só seguir as setas! Marcado no terreno com sinalética e painéis interpretativos, este percurso é conhecido como “Via Algarviana” e atravessa longitudinalmente a região. A via tem origem num antigo trilho religioso seguido pelos peregrinos que se dirigiam ao Promontório de Sagres onde foram encontradas as relíquias de São Vicente. Desde Alcoutim, junto ao rio Guadiana, até ao Cabo de São Vicente são cerca de 300 kms divididos em 14 setores, que têm início e fim em localidades com alojamento e restauração. Tudo pensado para podermos adaptar o trajeto ao ritmo de cada um, ou escolher apenas os troços que nos interessam.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\APinto\\anaconda3\\envs\\projeto_apspacy\\lib\\site-packages\\stanza\\models\\common\\beam.py:86: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  prevK = bestScoresId // numWords\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(pttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.sentences[0].print_dependencies() #sentences contains a list where each item contains a single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stanza.models.common.doc.Sentence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(doc.sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  {\n",
       "    \"id\": [\n",
       "      1,\n",
       "      2\n",
       "    ],\n",
       "    \"text\": \"No\",\n",
       "    \"start_char\": 0,\n",
       "    \"end_char\": 2\n",
       "  },\n",
       "  {\n",
       "    \"id\": 1,\n",
       "    \"text\": \"Em\",\n",
       "    \"lemma\": \"em\",\n",
       "    \"upos\": \"ADP\"\n",
       "  },\n",
       "  {\n",
       "    \"id\": 2,\n",
       "    \"text\": \"o\",\n",
       "    \"lemma\": \"o\",\n",
       "    \"upos\": \"DET\",\n",
       "    \"feats\": \"Definite=Def|Gender=Masc|Number=Sing|PronType=Art\"\n",
       "  },\n",
       "  {\n",
       "    \"id\": 3,\n",
       "    \"text\": \"interior\",\n",
       "    \"lemma\": \"interior\",\n",
       "    \"upos\": \"NOUN\",\n",
       "    \"feats\": \"Gender=Masc|Number=Sing\",\n",
       "    \"start_char\": 3,\n",
       "    \"end_char\": 11\n",
       "  },\n",
       "  {\n",
       "    \"id\": 4,\n",
       "    \"text\": \"tranquilo\",\n",
       "    \"lemma\": \"tranquilo\",\n",
       "    \"upos\": \"ADJ\",\n",
       "    \"feats\": \"Gender=Masc|Number=Sing\",\n",
       "    \"start_char\": 12,\n",
       "    \"end_char\": 21\n",
       "  },\n",
       "  {\n",
       "    \"id\": 5,\n",
       "    \"text\": \"e\",\n",
       "    \"lemma\": \"e\",\n",
       "    \"upos\": \"CCONJ\",\n",
       "    \"start_char\": 22,\n",
       "    \"end_char\": 23\n",
       "  },\n",
       "  {\n",
       "    \"id\": 6,\n",
       "    \"text\": \"verdejante\",\n",
       "    \"lemma\": \"verdejante\",\n",
       "    \"upos\": \"ADJ\",\n",
       "    \"feats\": \"Gender=Masc|Number=Sing\",\n",
       "    \"start_char\": 24,\n",
       "    \"end_char\": 34\n",
       "  },\n",
       "  {\n",
       "    \"id\": 7,\n",
       "    \"text\": \"há\",\n",
       "    \"lemma\": \"haver\",\n",
       "    \"upos\": \"VERB\",\n",
       "    \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "    \"start_char\": 35,\n",
       "    \"end_char\": 37\n",
       "  },\n",
       "  {\n",
       "    \"id\": 8,\n",
       "    \"text\": \"um\",\n",
       "    \"lemma\": \"um\",\n",
       "    \"upos\": \"DET\",\n",
       "    \"feats\": \"Definite=Ind|Gender=Masc|Number=Sing|PronType=Art\",\n",
       "    \"start_char\": 38,\n",
       "    \"end_char\": 40\n",
       "  },\n",
       "  {\n",
       "    \"id\": 9,\n",
       "    \"text\": \"Algarve\",\n",
       "    \"lemma\": \"Algarve\",\n",
       "    \"upos\": \"PROPN\",\n",
       "    \"feats\": \"Gender=Masc|Number=Sing\",\n",
       "    \"start_char\": 41,\n",
       "    \"end_char\": 48\n",
       "  },\n",
       "  {\n",
       "    \"id\": 10,\n",
       "    \"text\": \"diferente\",\n",
       "    \"lemma\": \"diferente\",\n",
       "    \"upos\": \"ADJ\",\n",
       "    \"feats\": \"Gender=Masc|Number=Sing\",\n",
       "    \"start_char\": 49,\n",
       "    \"end_char\": 58\n",
       "  },\n",
       "  {\n",
       "    \"id\": 11,\n",
       "    \"text\": \"que\",\n",
       "    \"lemma\": \"que\",\n",
       "    \"upos\": \"PRON\",\n",
       "    \"feats\": \"Gender=Masc|Number=Sing|PronType=Rel\",\n",
       "    \"start_char\": 59,\n",
       "    \"end_char\": 62\n",
       "  },\n",
       "  {\n",
       "    \"id\": 12,\n",
       "    \"text\": \"esconde\",\n",
       "    \"lemma\": \"esconder\",\n",
       "    \"upos\": \"VERB\",\n",
       "    \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "    \"start_char\": 63,\n",
       "    \"end_char\": 70\n",
       "  },\n",
       "  {\n",
       "    \"id\": 13,\n",
       "    \"text\": \"aldeias\",\n",
       "    \"lemma\": \"aldeia\",\n",
       "    \"upos\": \"NOUN\",\n",
       "    \"feats\": \"Gender=Fem|Number=Plur\",\n",
       "    \"start_char\": 71,\n",
       "    \"end_char\": 78\n",
       "  },\n",
       "  {\n",
       "    \"id\": 14,\n",
       "    \"text\": \"tradicionais\",\n",
       "    \"lemma\": \"tradicional\",\n",
       "    \"upos\": \"ADJ\",\n",
       "    \"feats\": \"Gender=Fem|Number=Plur\",\n",
       "    \"start_char\": 79,\n",
       "    \"end_char\": 91\n",
       "  },\n",
       "  {\n",
       "    \"id\": 15,\n",
       "    \"text\": \"e\",\n",
       "    \"lemma\": \"e\",\n",
       "    \"upos\": \"CCONJ\",\n",
       "    \"start_char\": 92,\n",
       "    \"end_char\": 93\n",
       "  },\n",
       "  {\n",
       "    \"id\": 16,\n",
       "    \"text\": \"paisagens\",\n",
       "    \"lemma\": \"paisagem\",\n",
       "    \"upos\": \"NOUN\",\n",
       "    \"feats\": \"Gender=Fem|Number=Plur\",\n",
       "    \"start_char\": 94,\n",
       "    \"end_char\": 103\n",
       "  },\n",
       "  {\n",
       "    \"id\": 17,\n",
       "    \"text\": \"espetaculares\",\n",
       "    \"lemma\": \"espetacular\",\n",
       "    \"upos\": \"ADJ\",\n",
       "    \"feats\": \"Gender=Fem|Number=Plur\",\n",
       "    \"start_char\": 104,\n",
       "    \"end_char\": 117\n",
       "  },\n",
       "  {\n",
       "    \"id\": 18,\n",
       "    \"text\": \".\",\n",
       "    \"lemma\": \".\",\n",
       "    \"upos\": \"PUNCT\",\n",
       "    \"start_char\": 117,\n",
       "    \"end_char\": 118\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': (1, 2), 'text': 'No', 'start_char': 0, 'end_char': 2}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast the first sentence object into a python dictionary\n",
    "doc_dict = doc.sentences[0].to_dict() #the key and value pairs in these dictionaries contain the linguistic annotations for each Token\n",
    "\n",
    "# Get the dictionary for the first Token\n",
    "doc_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'text': 'Em', 'lemma': 'em', 'upos': 'ADP'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'text', 'start_char', 'end_char'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'em'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict[1]['lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy-stanza\n",
    "import spacy_stanza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 12:09:12 WARNING: Language pt package default expects mwt, which has been added\n",
      "2022-05-06 12:09:12 INFO: Loading these models for language: pt (Portuguese):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | bosque  |\n",
      "| mwt       | bosque  |\n",
      "| pos       | bosque  |\n",
      "| lemma     | bosque  |\n",
      "=======================\n",
      "\n",
      "2022-05-06 12:09:12 INFO: Use device: cpu\n",
      "2022-05-06 12:09:12 INFO: Loading: tokenize\n",
      "2022-05-06 12:09:12 INFO: Loading: mwt\n",
      "2022-05-06 12:09:12 INFO: Loading: pos\n",
      "2022-05-06 12:09:12 INFO: Loading: lemma\n",
      "2022-05-06 12:09:12 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em em ADP  \n",
      "o o DET  \n",
      "interior interior NOUN  \n",
      "tranquilo tranquilo ADJ  \n",
      "e e CCONJ  \n",
      "verdejante verdejante ADJ  \n",
      "há haver VERB  \n",
      "um um DET  \n",
      "Algarve Algarve PROPN  \n",
      "diferente diferente ADJ  \n",
      "que que PRON  \n",
      "esconde esconder VERB  \n",
      "aldeias aldeia NOUN  \n",
      "tradicionais tradicional ADJ  \n",
      "e e CCONJ  \n",
      "paisagens paisagem NOUN  \n",
      "espetaculares espetacular ADJ  \n",
      ". . PUNCT  \n",
      "O o DET  \n",
      "caminho caminho NOUN  \n",
      "para para SCONJ  \n",
      "chegar chegar VERB  \n",
      "a a ADP  \n",
      "este este DET  \n",
      "mundo mundo NOUN  \n",
      "preservado preservar VERB  \n",
      "? ? PUNCT  \n",
      "Nada nada PRON  \n",
      "mais mais ADV  \n",
      "fácil fácil ADJ  \n",
      "… ... PUNCT  \n",
      "é ser AUX  \n",
      "só só ADV  \n",
      "seguir seguir VERB  \n",
      "as o DET  \n",
      "setas seta NOUN  \n",
      "! ! PUNCT  \n",
      "Marcado marcar VERB  \n",
      "em em ADP  \n",
      "o o DET  \n",
      "terreno terreno NOUN  \n",
      "com com ADP  \n",
      "sinalética sinalética NOUN  \n",
      "e e CCONJ  \n",
      "painéis painel NOUN  \n",
      "interpretativos interpretivotivo ADJ  \n",
      ", , PUNCT  \n",
      "este este DET  \n",
      "percurso percurso NOUN  \n",
      "é ser AUX  \n",
      "conhecido conhecer VERB  \n",
      "como como ADP  \n",
      "“ » PUNCT  \n",
      "Via Via PROPN  \n",
      "Algarviana Algarviana PROPN  \n",
      "” » PUNCT  \n",
      "e e CCONJ  \n",
      "atravessa atravessar VERB  \n",
      "longitudinalmente longitudinalmente ADV  \n",
      "a o DET  \n",
      "região região NOUN  \n",
      ". . PUNCT  \n",
      "A o DET  \n",
      "via via NOUN  \n",
      "tem ter VERB  \n",
      "origem origem NOUN  \n",
      "em em ADP  \n",
      "um um DET  \n",
      "antigo antigo ADJ  \n",
      "trilho trilho NOUN  \n",
      "religioso religioso ADJ  \n",
      "seguido seguir VERB  \n",
      "por por ADP  \n",
      "os o DET  \n",
      "peregrinos peregrino NOUN  \n",
      "que que PRON  \n",
      "se se PRON  \n",
      "dirigiam dirigir VERB  \n",
      "a a ADP  \n",
      "o o DET  \n",
      "Promontório Promontório PROPN  \n",
      "de de ADP  \n",
      "Sagres Sagres PROPN  \n",
      "onde onde PRON  \n",
      "foram ser AUX  \n",
      "encontradas encontrar VERB  \n",
      "as o DET  \n",
      "relíquias relíquia NOUN  \n",
      "de de ADP  \n",
      "São São PROPN  \n",
      "Vicente Vicente PROPN  \n",
      ". . PUNCT  \n",
      "Desde desde ADP  \n",
      "Alcoutim Alcoutim PROPN  \n",
      ", , PUNCT  \n",
      "junto junto ADV  \n",
      "a a ADP  \n",
      "o o DET  \n",
      "rio rio NOUN  \n",
      "Guadiana Guadiana PROPN  \n",
      ", , PUNCT  \n",
      "até até ADP  \n",
      "a a ADP  \n",
      "o o DET  \n",
      "Cabo Cabo PROPN  \n",
      "de de ADP  \n",
      "São São PROPN  \n",
      "Vicente Vicente PROPN  \n",
      "são ser AUX  \n",
      "cerca cerca ADV  \n",
      "de de ADP  \n",
      "300 300 NUM  \n",
      "kms kms NOUN  \n",
      "divididos dividir VERB  \n",
      "em em ADP  \n",
      "14 14 NUM  \n",
      "setores setor NOUN  \n",
      ", , PUNCT  \n",
      "que que PRON  \n",
      "têm ter VERB  \n",
      "início início NOUN  \n",
      "e e CCONJ  \n",
      "fim fim NOUN  \n",
      "em em ADP  \n",
      "localidades localidade NOUN  \n",
      "com com ADP  \n",
      "alojamento alojamento NOUN  \n",
      "e e CCONJ  \n",
      "restauração restauração NOUN  \n",
      ". . PUNCT  \n",
      "Tudo tudo PRON  \n",
      "pensado pensar VERB  \n",
      "para para SCONJ  \n",
      "podermos poder VERB  \n",
      "adaptar adaptar VERB  \n",
      "o o DET  \n",
      "trajeto trajeto NOUN  \n",
      "a a ADP  \n",
      "o o DET  \n",
      "ritmo ritmo NOUN  \n",
      "de de ADP  \n",
      "cada cada DET  \n",
      "um um NUM  \n",
      ", , PUNCT  \n",
      "ou ou CCONJ  \n",
      "escolher escolher VERB  \n",
      "apenas apenas ADV  \n",
      "os o DET  \n",
      "troços troço NOUN  \n",
      "que que PRON  \n",
      "nos nós PRON  \n",
      "interessam interessar VERB  \n",
      ". . PUNCT  \n",
      "()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\APinto\\anaconda3\\envs\\projeto_apspacy\\lib\\site-packages\\spacy\\language.py:1001: UserWarning: Due to multiword token expansion or an alignment issue, the original text has been replaced by space-separated expanded tokens.\n",
      "  doc = self._ensure_doc(text)\n",
      "c:\\Users\\APinto\\anaconda3\\envs\\projeto_apspacy\\lib\\site-packages\\spacy\\language.py:1001: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
      "Words: ['Em', 'o', 'interior', 'tranquilo', 'e', 'verdejante', 'há', 'um', 'Algarve', 'diferente', 'que', 'esconde', 'aldeias', 'tradicionais', 'e', 'paisagens', 'espetaculares', '.', 'O', 'caminho', 'para', 'chegar', 'a', 'este', 'mundo', 'preservado', '?', 'Nada', 'mais', 'fácil', '…', 'é', 'só', 'seguir', 'as', 'setas', '!', 'Marcado', 'em', 'o', 'terreno', 'com', 'sinalética', 'e', 'painéis', 'interpretativos', ',', 'este', 'percurso', 'é', 'conhecido', 'como', '“', 'Via', 'Algarviana', '”', 'e', 'atravessa', 'longitudinalmente', 'a', 'região', '.', 'A', 'via', 'tem', 'origem', 'em', 'um', 'antigo', 'trilho', 'religioso', 'seguido', 'por', 'os', 'peregrinos', 'que', 'se', 'dirigiam', 'a', 'o', 'Promontório', 'de', 'Sagres', 'onde', 'foram', 'encontradas', 'as', 'relíquias', 'de', 'São', 'Vicente', '.', 'Desde', 'Alcoutim', ',', 'junto', 'a', 'o', 'rio', 'Guadiana', ',', 'até', 'a', 'o', 'Cabo', 'de', 'São', 'Vicente', 'são', 'cerca', 'de', '300', 'kms', 'divididos', 'em', '14', 'setores', ',', 'que', 'têm', 'início', 'e', 'fim', 'em', 'localidades', 'com', 'alojamento', 'e', 'restauração', '.', 'Tudo', 'pensado', 'para', 'podermos', 'adaptar', 'o', 'trajeto', 'a', 'o', 'ritmo', 'de', 'cada', 'um', ',', 'ou', 'escolher', 'apenas', 'os', 'troços', 'que', 'nos', 'interessam', '.']\n",
      "Entities: []\n",
      "  doc = self._ensure_doc(text)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy_stanza.load_pipeline(\"pt\", processors='tokenize,pos,lemma') # This package wraps the Stanza (formerly StanfordNLP) library, so you can use Stanford's models as a spaCy pipeline. Using this wrapper, you'll be able to use the following annotations, computed by your pretrained stanza model\n",
    "doc = nlp(pttext)\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_)\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Provide Stanza pipeline settings following the Pipeline API:\n",
    "\n",
    "# # Initialize a German pipeline with the `hdt` package\n",
    "# nlp = spacy_stanza.load_pipeline(\"de\", package=\"hdt\")\n",
    "\n",
    "# #### Tokenize with spaCy rather than the statistical tokenizer (only for English):\n",
    "\n",
    "# nlp = spacy_stanza.load_pipeline(\"en\", processors= {\"tokenize\": \"spacy\"})\n",
    "\n",
    "# #### Provide any additional processor settings as additional keyword arguments:\n",
    "\n",
    "# # Provide pretokenized texts (whitespace tokenization)\n",
    "# nlp = spacy_stanza.load_pipeline(\"de\", tokenize_pretokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4805078708f9348296c00a2a4763f3feb08acd904b18372f621722e3508fa81"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('projeto_apspacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
